{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as Datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from RES_VAE import VAE as AE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "imageSize = 64\n",
    "lr = 1e-4\n",
    "nepoch = 100\n",
    "root = \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "GPU_indx  = 0\n",
    "device = torch.device(GPU_indx if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_STL10(transform, batch_size, download = True, root = \"/data\"):\n",
    "    print(\"Loading trainset...\")\n",
    "    trainset = Datasets.STL10(root=root, split='unlabeled', transform=transform, download=download)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    \n",
    "    print(\"Loading testset...\")\n",
    "    testset = Datasets.STL10(root=root, split='test', download=download, transform=transform)\n",
    "\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "def vae_loss(recon, x, mu, logvar):\n",
    "    recon_loss = F.binary_cross_entropy_with_logits(recon, x)\n",
    "    KL_loss = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).mean()\n",
    "    loss = recon_loss + 0.01 * KL_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extractor <br>\n",
    "Using a pre-tranined VGG-16 we insert an empty layer (after a relu) to capture the feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty layer that will simply record the feature map passed to it.\n",
    "class GetFeatures(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GetFeatures, self).__init__()\n",
    "        self.features = None\n",
    "    def forward(self, x):\n",
    "        self.features = x\n",
    "        return x\n",
    "\n",
    "#download the pre-trained weights of the VGG-16 and append them to an array of layers .\n",
    "#we insert a layers_deep layer after a relu layer.\n",
    "#layers_deep controls how deep we go into the network\n",
    "def get_feature_extractor(layers_deep = 7):\n",
    "    C_net = models.vgg16(pretrained=True).to(device)\n",
    "    C_net = C_net.eval()\n",
    "    \n",
    "    layers = []\n",
    "    for i in range(layers_deep):\n",
    "        layers.append(C_net.features[i])\n",
    "        if isinstance(C_net.features[i], nn.ReLU):\n",
    "            layers.append(GetFeatures())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "#this function calculates the L2 loss (MSE) on the feature maps copied by the layers_deep\n",
    "#between the reconstructed image and the origional\n",
    "def feature_loss(img, recon_data, Features):\n",
    "    img_cat = torch.cat((img, torch.sigmoid(recon_data)), 0)\n",
    "    out = Features(img_cat)\n",
    "    loss = 0\n",
    "    c = 0\n",
    "    for i in range(len(Features)):\n",
    "        if isinstance(Features[i], GetFeatures):\n",
    "            loss += (Features[i].features[:(img.shape[0])] - Features[i].features[(img.shape[0]):]).pow(2).mean()\n",
    "            c+=1\n",
    "    return loss/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_Linear(epoch_max, epoch, lr):\n",
    "    lr_adj = ((epoch_max-epoch)/epoch_max)*lr\n",
    "    set_lr(lr = lr_adj)\n",
    "\n",
    "def set_lr(lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(imageSize), T.ToTensor()])\n",
    "\n",
    "trainloader, testloader = get_data_STL10(transform, batchSize, download = True, root = root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a test image batch from the testloader to visualise the reconstruction quality\n",
    "dataiter = iter(testloader)\n",
    "test_images = dataiter.next()[0]\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(test_images[0:8])\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_net = AE(channel_in = 3).to(device)\n",
    "Features = get_feature_extractor()\n",
    "# setup optimizer\n",
    "optimizer = optim.Adam(vae_net.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "BCE_Loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_log = []\n",
    "lowest_test_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(nepoch):\n",
    "    lr_Linear(nepoch, epoch, lr)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        recon_data, mu, logvar = vae_net(data[0].to(device))\n",
    "        \n",
    "        loss = vae_loss(recon_data, data[0].to(device), mu, logvar)\n",
    "        \n",
    "        loss_feature = feature_loss(data[0].to(device), recon_data, Features)\n",
    "\n",
    "        loss += loss_feature\n",
    "        \n",
    "        loss_log.append(loss.item())\n",
    "        vae_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        clear_output(True)\n",
    "        print('Epoch: [%d/%d], Itteration: [%d/%d] loss: %.4f' \n",
    "              % (epoch, nepoch, i, len(trainloader), loss.item()))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        recon_data, _, _ = vae_net(test_images.to(device), Train = False)\n",
    "        test_loss = BCE_Loss(recon_data, test_images.to(device))\n",
    "        \n",
    "    if test_loss < lowest_test_loss:\n",
    "        lowest_test_loss = test_loss\n",
    "        torch.save(vae_net.state_dict(), \"Models/VAE_STL10\" + str(imageSize) +\".pt\" )\n",
    "        vutils.save_image(torch.cat((torch.sigmoid(recon_data.cpu()), test_images),2),\"%s/VAE_%s_%d.png\" % (\"Results\" , \"VAE_STL10\", imageSize))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
